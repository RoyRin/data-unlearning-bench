{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch as ch\n",
    "from pathlib import Path\n",
    "from notebooks.utils import get_executor, submit_job\n",
    "from unlearning.training.train import wrapper_for_train_cifar10_on_subset_submitit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Oracles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "executor = get_executor(\"oracles\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get boolean masks from forget indices "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_SAVE_PATH = Path(\"/mnt/xfs/projects/untrak/MATCHING/oracles/CIFAR10\")\n",
    "FORGET_SETS_PATH = Path(\"/mnt/xfs/projects/untrak/MATCHING/forget_set_inds/CIFAR10\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_models_per_job = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using masks so that we can\n",
    "# re-use the wrapper function wrapper_for_train_cifar10_on_subset_submitit\n",
    "\n",
    "# as an artifact, I'm saving N_models_per_job copies of the same mask\n",
    "# so that we can use idx_start and n_models directly in the wrapper function\n",
    "\n",
    "MASK_PATHS = []\n",
    "\n",
    "recreate_masks = False\n",
    "\n",
    "for SET_PATH in sorted(list(FORGET_SETS_PATH.iterdir())):\n",
    "    key = SET_PATH.stem\n",
    "    print(f\"key: {key}\")\n",
    "    print(f\"forget_set_path: {SET_PATH}\")\n",
    "    if recreate_masks:\n",
    "        forget_set = np.load(SET_PATH)\n",
    "        mask = np.ones(50_000)\n",
    "        mask[forget_set] = 0\n",
    "        mask = mask.astype(bool)\n",
    "        mask = np.stack([mask] * N_models_per_job, axis=0)\n",
    "        print(mask.shape)\n",
    "\n",
    "    MASK_DIR = BASE_SAVE_PATH / key\n",
    "    MASK_PATH = MASK_DIR / \"mask.npy\"\n",
    "    print(MASK_PATH)\n",
    "    MASK_PATHS.append(MASK_PATH)\n",
    "    if recreate_masks:\n",
    "        MASK_DIR.mkdir(exist_ok=True, parents=True)\n",
    "        np.save(MASK_PATH, mask)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_models_per_forget_set = 250\n",
    "N_jobs_per_forget_set = N_models_per_forget_set // N_models_per_job\n",
    "print(N_jobs_per_forget_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MASK_PATHS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1, 10):\n",
    "    print(i)\n",
    "    print(np.load(MASK_PATHS[i - 1]).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Send jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_args = []\n",
    "\n",
    "for MASK_PATH in MASK_PATHS:\n",
    "    CKPT_PATH = MASK_PATH.parent\n",
    "    for i in range(N_jobs_per_forget_set):\n",
    "        idx_start = i * N_models_per_job\n",
    "        model_id_offset = idx_start\n",
    "        should_save_train_logits = True\n",
    "        should_save_val_logits = True\n",
    "        batch_args.append([MASK_PATH,\n",
    "                           0,\n",
    "                           N_models_per_job,\n",
    "                           CKPT_PATH,\n",
    "                           should_save_train_logits,\n",
    "                           should_save_val_logits,\n",
    "                           model_id_offset\n",
    "                           ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_args[11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_array = submit_job(executor,\n",
    "                       wrapper_for_train_cifar10_on_subset_submitit,\n",
    "                       batch_args,\n",
    "                       batch=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "executor = get_executor(\"full_models\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_SAVE_PATH = Path(\"/mnt/xfs/projects/untrak/MATCHING/full_models/CIFAR10\")\n",
    "BASE_SAVE_PATH.mkdir(exist_ok=True, parents=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_models_per_forget_set = 200\n",
    "N_models_per_job = 10\n",
    "N_jobs_per_forget_set = N_models_per_forget_set // N_models_per_job\n",
    "print(N_jobs_per_forget_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_args = []\n",
    "\n",
    "should_save_train_logits = True\n",
    "should_save_val_logits = True\n",
    "DUMMY_MASK_PATH = \"\"  # train on all samples\n",
    "\n",
    "for i in range(N_jobs_per_forget_set):\n",
    "    model_id_offset = i * N_models_per_job\n",
    "    batch_args.append([DUMMY_MASK_PATH,\n",
    "                       0,\n",
    "                       N_models_per_job,\n",
    "                       BASE_SAVE_PATH,\n",
    "                       should_save_train_logits,\n",
    "                       should_save_val_logits,\n",
    "                       model_id_offset\n",
    "                       ])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_args[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_array = submit_job(executor,\n",
    "                       wrapper_for_train_cifar10_on_subset_submitit,\n",
    "                       batch_args,\n",
    "                       batch=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Post-process logits and create margins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CKPT_DIRS = [MASK_PATH.parent for MASK_PATH in MASK_PATHS] + [BASE_SAVE_PATH]\n",
    "CKPT_DIRS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unlearning.datasets.cifar10 import get_cifar_dataloader\n",
    "from tqdm.autonotebook import tqdm\n",
    "\n",
    "train_ds = get_cifar_dataloader().dataset\n",
    "train_labels = [train_ds[i][1] for i in range(len(train_ds))]\n",
    "print(train_labels[0])\n",
    "\n",
    "val_ds = get_cifar_dataloader(split=\"val\").dataset\n",
    "val_labels = [val_ds[i][1] for i in range(len(val_ds))]\n",
    "val_labels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_val = 10_000\n",
    "bindex = np.arange(N_val)\n",
    "for CKPT_PATH in tqdm(CKPT_DIRS):\n",
    "    for val_logits_path in CKPT_PATH.rglob(\"val_logits*\"):\n",
    "        logits_id = val_logits_path.stem.split(\"_\")[-1]\n",
    "        val_logits = ch.load(val_logits_path)\n",
    "        val_correct = val_logits[bindex, val_labels].clone()\n",
    "        val_logits[bindex, val_labels] = -ch.inf\n",
    "        val_margins = val_correct - val_logits.logsumexp(dim=1)\n",
    "        ch.save(val_margins, CKPT_PATH / f\"val_margins_{logits_id}.pt\")\n",
    "\n",
    "N_train = 50_000\n",
    "bindex = np.arange(N_train)\n",
    "for CKPT_PATH in tqdm(CKPT_DIRS):\n",
    "    for train_logits_path in CKPT_PATH.rglob(\"train_logits*\"):\n",
    "        logits_id = train_logits_path.stem.split(\"_\")[-1]\n",
    "        train_logits = ch.load(train_logits_path)\n",
    "        train_correct = train_logits[bindex, train_labels].clone()\n",
    "        train_logits[bindex, train_labels] = -ch.inf\n",
    "        train_margins = train_correct - train_logits.logsumexp(dim=1)\n",
    "        ch.save(train_margins, CKPT_PATH / f\"train_margins_{logits_id}.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Move margins and logits to single arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for CKPT_PATH in tqdm(CKPT_DIRS):\n",
    "    for array_name in [\"train_logits\", \"val_logits\", \"train_margins\", \"val_margins\"]:\n",
    "        all_arrays = []\n",
    "        N = 250 if \"oracle\" in str(CKPT_PATH) else 200\n",
    "        for i in range(N):\n",
    "            array_path = CKPT_PATH / f\"{array_name}_{i}.pt\"\n",
    "            array = ch.load(array_path)\n",
    "            all_arrays.append(array)\n",
    "        all_arrays = ch.stack(all_arrays)\n",
    "        ch.save(all_arrays, CKPT_PATH / f\"{array_name}_all.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ch.load(CKPT_DIRS[0] / \"train_logits_all.pt\").shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ch.load(CKPT_DIRS[-1] / \"val_margins_all.pt\").shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ch.load(CKPT_DIRS[-1] / \"val_margins_all.pt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
