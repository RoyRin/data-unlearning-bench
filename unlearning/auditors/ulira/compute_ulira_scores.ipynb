{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch as ch\n",
    "from pathlib import Path\n",
    "from unlearning.auditors.utils import (\n",
    "    loader_factory,\n",
    " )\n",
    "import yaml\n",
    "import numpy as np\n",
    "import torch as ch\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "from unlearning.auditors import ulira\n",
    "\n",
    "from unlearning import BASE_DIR, LOG_DIR, ULIRA_BASE_DIR\n",
    "\n",
    "\n",
    "\n",
    "def read_yaml(yaml_file):\n",
    "    with open(yaml_file, \"r\") as f:\n",
    "        config = yaml.safe_load(f)\n",
    "    return config\n",
    "\n",
    "\n",
    "def load_model(path, model_factory, ds_name):\n",
    "    model = model_factory(ds_name)\n",
    "    loaded_model = ch.load(path)\n",
    "    first_key = list(loaded_model.keys())[0]\n",
    "    if \"model\" in first_key:\n",
    "        model.load_state_dict(loaded_model)\n",
    "\n",
    "    else:\n",
    "        # add \".model\" to each key in k,vs\n",
    "        loaded_model = {f\"model.{k}\": v for k, v in loaded_model.items()}\n",
    "        model.load_state_dict(loaded_model)\n",
    "    return model\n",
    "\n",
    "\n",
    "#unlearnings_per_model = 20\n",
    "unlearnings_per_model = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ULIRA_BASE_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute margins from logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute margins from the logits\n",
    "# ORACLE MODEL margin computation\n",
    "dataset_name = \"CIFAR10\"\n",
    "model_dir_name = \"final_models\"\n",
    "model_dir_name = \"resnet_long\"\n",
    "\n",
    "train_f = ULIRA_BASE_DIR / model_dir_name# / \"train_margins_all.pt\"\n",
    "val_f = ULIRA_BASE_DIR / model_dir_name #/ \"val_margins_all.pt\"\n",
    "\n",
    "\n",
    "\n",
    "def load_individual_margins(dir_, max_count=300):\n",
    "    \"\"\" load individual margins from a directory, as 1 mega tensor\"\"\"\n",
    "\n",
    "    def get_num(p):\n",
    "        return int(p.name.split(\"_\")[2].split(\".\")[0])\n",
    "\n",
    "    train_margins = list(dir_.glob(\"train_margins_*.pt\"))\n",
    "    val_margins = list(dir_.glob(\"val_margins_*.pt\"))\n",
    "\n",
    "    val_margins = sorted(val_margins, key=get_num)\n",
    "    train_margins = sorted(train_margins, key=get_num)\n",
    "    # load and concatenate\n",
    "    all_train_margins = []\n",
    "    all_val_margins = []\n",
    "    for i in range(max_count):\n",
    "        if i % 10 == 0:\n",
    "            print(f\"loading {i}\")\n",
    "        all_train_margins.append(ch.tensor(ch.load(train_margins[i])))\n",
    "        all_val_margins.append(ch.tensor(ch.load(val_margins[i])))\n",
    "\n",
    "    return all_train_margins, all_val_margins\n",
    "\n",
    "\n",
    "\n",
    "if model_dir_name == \"final_models\":\n",
    "    ds_name = \"CIFAR10\"\n",
    "    #forget_masks = ulira.get_ulira_forget_mask(ds_name, class_5_range=1000, overwrite=False )print(f\"original training_masks- shape {training_masks.shape}\")\n",
    "    # which points to forget\n",
    "    ulira_train_all_margins, ulira_val_all_margins = ulira.load_all_ulira_margins(\n",
    "        ds_name)\n",
    "\n",
    "    all_oracle_margins_ulira = ch.cat([\n",
    "        ch.tensor(ulira_train_all_margins.T),\n",
    "        ch.tensor(ulira_val_all_margins.T)\n",
    "    ]).T\n",
    "\n",
    "else:\n",
    "    model_count = 300\n",
    "\n",
    "    ulira_train_all_margins, ulira_val_all_margins = load_individual_margins(\n",
    "        train_f, model_count)\n",
    "    # stakc em\n",
    "    #print(ulira_train_all_margins[0].shape)\n",
    "\n",
    "    ulira_train_all_margins = ch.stack(ulira_train_all_margins)\n",
    "    # squash the margins into a single tensor\n",
    "    ulira_val_all_margins = ch.stack(ulira_val_all_margins)\n",
    "\n",
    "    all_oracle_margins_ulira = ch.cat([\n",
    "        ch.tensor(ulira_train_all_margins).T,\n",
    "        ch.tensor(ulira_val_all_margins).T\n",
    "    ]).T\n",
    "\n",
    "    #ch.cat([all_train_margins, all_val_margins])\n",
    "all_oracle_margins_ulira.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(ulira_train_all_margins[0])\n",
    "ulira_val_all_margins.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Issues that could be :\n",
    "1. incorrectly reading the forget masks\n",
    "2. incorrectly reading the align masks\n",
    "3. incorectly reading the val margins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_masks = ulira.get_ulira_training_masks()\n",
    "\n",
    "\n",
    "\n",
    "# Repeat each row n times\n",
    "#result = all_oracle_margins_ulira.repeat(unlearnings_per_model, 1).view(-1, all_oracle_margins_ulira.size(1))\n",
    "\n",
    "dont_repeat_them = False\n",
    "print(f\"do tiling for masks and for oracle margins\")\n",
    "if dont_repeat_them:\n",
    "    repeated_training_masks = np.repeat(training_masks, unlearnings_per_model, axis=0)\n",
    "\n",
    "    repeated_all_oracle_margins_ulira = all_oracle_margins_ulira.clone()\n",
    "    repeated_all_oracle_margins_ulira = repeated_all_oracle_margins_ulira.repeat_interleave(unlearnings_per_model, dim=0)\n",
    "    #\n",
    "else:\n",
    "\n",
    "    non_repeated_training_masks = training_masks.copy()\n",
    "    non_repeated_all_oracle_margins_ulira = all_oracle_margins_ulira.clone()\n",
    "\n",
    "    training_masks = np.repeat(training_masks, unlearnings_per_model, axis=0)\n",
    "    all_oracle_margins_ulira = all_oracle_margins_ulira.repeat_interleave(unlearnings_per_model, dim=0)\n",
    "    #repeated_all_oracle_margins_ulira = all_oracle_margins_ulira.clone()\n",
    "\n",
    "print(f\"training_masks - shape {training_masks.shape}\")\n",
    "\n",
    "print(f\"all_oracle_margins_ulira - shape {all_oracle_margins_ulira.shape}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unlearning.auditors.ulira_plans import get_ulira_forget_masks, load_ulira_forget_masks, load_all_ulira_forget_masks\n",
    "forget_masks = load_all_ulira_forget_masks()\n",
    "#forget_masks_40 = load_ulira_forget_masks(original_model_count = 256)\n",
    "#forget_masks = np.concatenate(forget_masks_40)\n",
    "# save the forget masks\n",
    "print(f\"loadded - {forget_masks.shape}\")\n",
    "def get_forgettable_indices(forget_masks):\n",
    "    \"\"\" extract out the forgettable indices from the forget_masks\"\"\"\n",
    "    forgettable_indices = set([])\n",
    "    #for forget_group in forget_masks:\n",
    "    for row in forget_masks:\n",
    "        l = set(row.nonzero()[0])\n",
    "        forgettable_indices= forgettable_indices.union(l)\n",
    "    # this value should be 1000\n",
    "    #if len(forgettable_indices) != 1000:\n",
    "    #    raise ValueError(\"forget_points should have 1000 points\")\n",
    "    # for each of these points, compute a ulira score using the margins\n",
    "    forgettable_indices= list(forgettable_indices)\n",
    "    return forgettable_indices\n",
    "forgettable_indices = get_forgettable_indices(forget_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if False:\n",
    "    base_dir = Path(\"/n/home04/rrinberg/data_dir__holylabs/unlearning/precomputed_models/ULIRA_clean\")\n",
    "    ga_name = 'CIFAR10____benchmark_GA_wrapper__dataset=CIFAR10__num_epochs=5__learning_rate=0.001__batch_size=64__forget_batch_size=64'\n",
    "if False:\n",
    "    gd_name = 'CIFAR10____benchmark_GD_wrapper__dataset=CIFAR10__num_epochs=5__learning_rate=0.001__forget_batch_size=64'\n",
    "\n",
    "\n",
    "    scrub_name = \"CIFAR10____scrub__dataset=CIFAR10__num_epochs=10__learning_rate=0.01__forget_batch_size=32__beta=0.999__retain_batch_size=64__maximization_epochs=3\"\n",
    "\n",
    "    ga_name = \"CIFAR10____benchmark_GA_wrapper__dataset=CIFAR10__num_epochs=5__learning_rate=0.001__batch_size=64__forget_batch_size=64\"\n",
    "\n",
    "def sort_by_last_num(s):\n",
    "\n",
    "    last = str(s).split(\"__\")[-1]\n",
    "    return int(last[:-len(\".pt\")])\n",
    "\n",
    "\n",
    "base_dir = ULIRA_BASE_DIR / \"results\"\n",
    "ga_name = \"CIFAR10____benchmark_GA_wrapper__dataset=CIFAR10__num_epochs=5__learning_rate=0.001__batch_size=64__forget_batch_size=64\"\n",
    "ga_uliras_pts = sorted(list((base_dir / ga_name / \"ulira\").glob(\"*.pt\")), key=sort_by_last_num)\n",
    "\n",
    "\n",
    "gd_name = \"CIFAR10____benchmark_GD_wrapper__dataset=CIFAR10__num_epochs=5__learning_rate=0.001__forget_batch_size=64\"\n",
    "\n",
    "scrub_name = 'CIFAR10____scrub__dataset=CIFAR10__num_epochs=10__learning_rate=0.01__forget_batch_size=32__beta=0.999__retain_batch_size=64__maximization_epochs=3'\n",
    "\n",
    "gd_uliras_pts = sorted(list((base_dir / gd_name / \"ulira\").glob(\"*.pt\")),\n",
    "                        key=sort_by_last_num)\n",
    "\n",
    "scrub_uliras_pts = sorted(list(\n",
    "    (base_dir / scrub_name / \"ulira\").glob(\"*.pt\")),\n",
    "                            key=sort_by_last_num)\n",
    "\n",
    "print(f\"ga-  {len(ga_uliras_pts)}\")\n",
    "print(f\"gd { len(gd_uliras_pts)}\")\n",
    "print(f\"scrub - {len(scrub_uliras_pts)}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, pts in [(\"GD\", gd_uliras_pts), (\"GA\", ga_uliras_pts),\n",
    "                  (\"Scrub\", scrub_uliras_pts)]:\n",
    "    print(name)\n",
    "    nums = []\n",
    "    for p in pts:\n",
    "        num = int(p.name.split(\"__\")[-1][:-len(\".pt\")])\n",
    "        nums.append(num)\n",
    "    expected = list(range(0, 2000, 40))\n",
    "    missing = set(expected) - set(nums)\n",
    "    print(sorted(list(missing)))\n",
    "    indices = sorted(np.array(list(missing)) / 20)\n",
    "    print(f\"indices {indices}\")\n",
    "# scrub - need to do : 0 (0)\n",
    "# GD - 350 (7)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "8,30,54,56,58,66,68,78,80,82,84,96"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ga_uliras_pts[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_merge(uliras_pts):\n",
    "    all_margins = []\n",
    "    for pt in uliras_pts:\n",
    "        margin = ch.load(pt)\n",
    "        all_margins.append(margin)\n",
    "    # repeat the marings by the number of unlearnings\n",
    "\n",
    "    ret = ch.cat(all_margins, dim=0)\n",
    "    #ret = ret.repeat_interleave(unlearnings_per_model, dim=0)\n",
    "    return ret\n",
    "\n",
    "ga_uliras_pts_all = load_and_merge(ga_uliras_pts)\n",
    "\n",
    "#gd_uliras_pts_all = load_and_merge(gd_uliras_pts)\n",
    "#scrub_uliras_pts_all = load_and_merge(scrub_uliras_pts)\n",
    "\n",
    "print(f\"unlearned models : {ga_uliras_pts_all.shape}\")\n",
    "print(f\"oracles - {all_oracle_margins_ulira.shape}\")\n",
    "\n",
    "print(f\"doing scrub_uliras_pts_all Descent\")\n",
    "all_unlearned_margins_ulira = ga_uliras_pts_all\n",
    "\n",
    "all_oracle_margins_ulira = all_oracle_margins_ulira[:all_unlearned_margins_ulira.shape[0]]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nums = []\n",
    "for p in ga_uliras_pts:\n",
    "    i = p.name.split(\"__\")[-1][:-len(\".pt\")]\n",
    "    num = int(i)\n",
    "    nums.append(num)\n",
    "\n",
    "expected = list(range(0, 2000, unlearnings_per_model ))\n",
    "a = list(set(expected) - set(nums))\n",
    "print(f\"missing : {sorted(a)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_forget_mask_and_training_mask(index):\n",
    "    \"\"\" get the forget mask and training mask for a given index\"\"\"\n",
    "    original_model_i = index // unlearnings_per_model\n",
    "    # Note: forget_masks is a concatenation of all the forget masks,\n",
    "    return training_masks[original_model_i], forget_masks[index]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get 200 points from class 5 that are not from the forgettable_points\n",
    "#forgettable_indices\n",
    "def get_test_points_for_ulira(forget_indices, forgettable_indices, num_test_points=200, seed = 42):\n",
    "    \"\"\"\n",
    "    get 200 points forgettable points from class 5 that are not in the forget_indices\n",
    "    \"\"\"\n",
    "    np.random.seed(seed)\n",
    "    # copy forgettable_indices\n",
    "    class_5 = forgettable_indices.copy()\n",
    "    class_5 = np.array(list(set(class_5) - set(forget_indices)))\n",
    "    np.random.shuffle(class_5)\n",
    "    return list(class_5)[:num_test_points]\n",
    "\n",
    "def gaussian_pdf(x, mean, std):\n",
    "    return 1 / (std * np.sqrt(2 * np.pi)) * np.exp(-0.5 * ((x - mean) / std) ** 2)\n",
    "\n",
    "\n",
    "def single_ulira(\n",
    "        all_unlearned_margins: ch.Tensor,  # T x n\n",
    "        all_test_margins: ch.Tensor,  # T x n\n",
    "        unlearned_model_margin: float,\n",
    "        sample_ind,\n",
    "        threshold=0.5,\n",
    "        plot=False,\n",
    "        verbose=False,\n",
    "        drop_outliers=False):\n",
    "    \"\"\"\n",
    "    Compute the ULIRA (Unlearning Likelihood Ratio) results for each sample. for a single unlearned model.\n",
    "\n",
    "    Note: \n",
    "        1: (x,y) is likely a member of training (unlearned model)\n",
    "        0: (x,y) is likely a member of the oracle (oracle model)\n",
    "\n",
    "    Args:\n",
    "        all_unlearned_margins (ch.Tensor): Tensor of shape T x n containing the margins of all unlearned models.\n",
    "        all_oracle_margins (ch.Tensor): Tensor of shape T x n containing the margins of all oracle models.\n",
    "        hold_out_model (int): Index of the hold-out model.\n",
    "        threshold (float, optional): Threshold value for the likelihood ratio. Defaults to 0.5.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: Array of ULIRA results for each sample, where 1 indicates the likelihood ratio is above the threshold, and 0 otherwise.\n",
    "    \"\"\"\n",
    "    #\n",
    "    test_margins = all_test_margins[:, sample_ind].cpu().numpy()\n",
    "\n",
    "    unlearned_margins = all_unlearned_margins[:, sample_ind].cpu().numpy()\n",
    "\n",
    "    #\n",
    "    #unlearned_model_margin = unlearned_margins[hold_out_model]\n",
    "    #other_unlearned_models = np.delete(unlearned_margins, hold_out_model)\n",
    "\n",
    "    # fit gaussians\n",
    "    def fit_gaussian(margins, drop_num=5):\n",
    "        m = sorted(margins)\n",
    "        # remove the top and bottom 3%\n",
    "        if drop_outliers:\n",
    "            m = m[drop_num:-drop_num]\n",
    "\n",
    "        mean, std = np.mean(m), np.std(m)\n",
    "        return mean, std\n",
    "\n",
    "    test_mean, test_std = fit_gaussian(test_margins)\n",
    "    unlearned_mean, unlearned_std = fit_gaussian(unlearned_margins)\n",
    "\n",
    "    #print(f\"aaa ({np.round(oracle_mean,2)}, {np.round(oracle_std,2)}) vs ({np.round(unlearned_mean,2)}, {np.round(unlearned_std,2)})\")\n",
    "    # compute LIRA\n",
    "    unlearned_model_margin = float(unlearned_model_margin)\n",
    "\n",
    "    oracle_prob = gaussian_pdf(unlearned_model_margin, test_mean, test_std)\n",
    "    unlearned_prob = gaussian_pdf(unlearned_model_margin, unlearned_mean,\n",
    "                                  unlearned_std)\n",
    "\n",
    "    likelihood_ratio = unlearned_prob / (unlearned_prob + oracle_prob)\n",
    "\n",
    "    # print(f\"likelihood_ratio - {likelihood_ratio} : type - {type(likelihood_ratio)}\")\n",
    "\n",
    "    likelihood_ratio = float(likelihood_ratio)\n",
    "    if verbose:\n",
    "        print(f\"unlearned_margins shape - {unlearned_margins.shape}\")\n",
    "        print(f\"oracle_margins shape - {test_margins.shape}\")\n",
    "        # print(f\"oracle_margins - {test_margins}\")\n",
    "\n",
    "    if plot:\n",
    "        # plot gaussians\n",
    "        plt.xlim(-20, 20)\n",
    "        x = np.linspace(-20, 20, 1000)\n",
    "\n",
    "        plt.hist(test_margins, bins=50, alpha=0.5, label=\"test\", density=True)\n",
    "        plt.hist(unlearned_margins,\n",
    "                 bins=50,\n",
    "                 alpha=0.5,\n",
    "                 label=\"unlearned\",\n",
    "                 density=True)\n",
    "        oracle_pdf = gaussian_pdf(x, test_mean, test_std)\n",
    "        unlearned_pdf = gaussian_pdf(x, unlearned_mean, unlearned_std)\n",
    "        num_pts = len(unlearned_margins)\n",
    "        num_unique_pts = len(np.unique(unlearned_margins))\n",
    "\n",
    "        plt.title(\n",
    "            f\"sample index: {sample_ind} | likelihood ratio: {round(likelihood_ratio,2):.2f} = {round(unlearned_prob,2)} / ({round(unlearned_prob,2)} + {round(oracle_prob,2)})\\n num pts: {num_pts} | num unique pts: {num_unique_pts}\"\n",
    "        )\n",
    "        plt.plot(x, oracle_pdf, label=\"oracle\")\n",
    "        plt.plot(x, unlearned_pdf, label=\"unlearned\")\n",
    "        plt.axvline(unlearned_model_margin, color=\"black\", linestyle=\"--\")\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "    # save result\n",
    "    return float(likelihood_ratio > threshold)\n",
    "\n",
    "\n",
    "\n",
    "#####\n",
    "def get_training_models_with_and_without(masks, index):\n",
    "    \"\"\"\n",
    "    return indices of models with and without the point\n",
    "    \"\"\"\n",
    "    m = masks[:, index].T\n",
    "\n",
    "    with_index, without_index = np.where(m == 1)[0], np.where(m == 0)[0]\n",
    "    return with_index, without_index\n",
    "\n",
    "\n",
    "\n",
    "def get_models_with_pt_forgotten(masks, forget_mask, sample_index):\n",
    "    \"\"\"\n",
    "    find the indices where the point is in the plan and in the forget mask\n",
    "    \"\"\"\n",
    "\n",
    "    models_with = []\n",
    "    models_inds_with, _ = get_training_models_with_and_without(\n",
    "    masks, sample_index)\n",
    "\n",
    "    for model_ind in models_inds_with:\n",
    "        if forget_mask[model_ind, sample_index] == 1:\n",
    "            models_with.append(model_ind)\n",
    "    return np.array(models_with)\n",
    "\n",
    "def get_models_with_pt_retained(masks, forget_mask, sample_index):\n",
    "    \"\"\"\n",
    "    find the indices where the point is in the plan and in the forget mask\n",
    "    \"\"\"\n",
    "\n",
    "    models_with = []\n",
    "    models_inds_with, _ = get_training_models_with_and_without(\n",
    "    masks, sample_index)\n",
    "\n",
    "    for model_ind in models_inds_with:\n",
    "        if forget_mask[model_ind, sample_index] == 0:\n",
    "            models_with.append(model_ind)\n",
    "    return np.array(models_with)\n",
    "#####\n",
    "\n",
    "def do_ulira_on_one_model(indices,\n",
    "                          correct_ulira_label,\n",
    "                          target_margins,\n",
    "                          shadow_unlearning_margins,\n",
    "                          shadow_oracle_margins,\n",
    "                          forget_masks,\n",
    "                          training_masks,\n",
    "                          plot_index=-1, verbose=  False ):\n",
    "    \"\"\"\n",
    "\n",
    "    \"\"\"\n",
    "    correct_ulira = 0\n",
    "    ulira_labels = []\n",
    "    for i, sample_index in enumerate(indices):\n",
    "        if i % 50 == 0:\n",
    "            print(f\"i - {i}/ {len(indices)} = {round(correct_ulira *100. / (i+1),2)}\")\n",
    "        # get models with x forgotten and models that never saw x\n",
    "        models_with_x_forgotten = get_models_with_pt_forgotten(\n",
    "            training_masks, forget_masks, sample_index)\n",
    "        _, models_without_x = get_training_models_with_and_without(\n",
    "            training_masks, sample_index)\n",
    "\n",
    "        num_models_with_x_forgotten = len(models_with_x_forgotten)\n",
    "        num_models_without_x = len(models_without_x)\n",
    "        if verbose:\n",
    "            print(f\"num_models_with_x_forgotten - {num_models_with_x_forgotten}\")\n",
    "            print(f\"num_models_without_x - {num_models_without_x}\")\n",
    "\n",
    "        max_models = 300\n",
    "\n",
    "        min_models = min(num_models_with_x_forgotten, num_models_without_x)\n",
    "        min_models = min(max_models, min_models)\n",
    "        #\n",
    "        #print(f\"min models - {min_models    }\")\n",
    "        #min_models = -1\n",
    "        models_with_x_forgotten = models_with_x_forgotten[:min_models]\n",
    "        models_without_x = models_without_x[:min_models]\n",
    "\n",
    "        # the margin of the target model on sample index\n",
    "        target_margin = target_margins[sample_index]\n",
    "\n",
    "        # we want to do a lira test between unlearned models that saw x\n",
    "        # and unlearned models that did not see x\n",
    "\n",
    "        ulira_label = single_ulira(\n",
    "            shadow_unlearning_margins[models_with_x_forgotten],\n",
    "            shadow_unlearning_margins[models_without_x],\n",
    "            target_margin,\n",
    "            sample_index,\n",
    "            plot=(i == plot_index), verbose= verbose)\n",
    "\n",
    "\n",
    "        if False:\n",
    "            ulira_label = single_ulira(\n",
    "                shadow_unlearning_margins[models_with_x_forgotten],\n",
    "                shadow_oracle_margins[models_without_x],\n",
    "                target_margin,\n",
    "                sample_index,\n",
    "                plot=(i == plot_index))\n",
    "        ulira_labels.append(ulira_label)\n",
    "        if ulira_label == correct_ulira_label:\n",
    "            correct_ulira += 1\n",
    "        plot_it_all = False# correct_ulira_label==0 #True\n",
    "        if plot_it_all:\n",
    "            if ulira_label == correct_ulira_label:\n",
    "                print(f\"plotting good boy - expecting {correct_ulira_label}, where 1 = forget, 0 = retain\")\n",
    "\n",
    "            else:\n",
    "                # plot it :\n",
    "\n",
    "                print(f\"plotting wrong boy - expecting {correct_ulira_label}, where 1 = forget, 0 = retain\")\n",
    "\n",
    "            ulira_label = single_ulira(\n",
    "                    shadow_unlearning_margins[models_with_x_forgotten],\n",
    "                    shadow_unlearning_margins[models_without_x],\n",
    "                    target_margin,\n",
    "                    sample_index,\n",
    "                    plot=True, verbose= verbose)\n",
    "\n",
    "    return correct_ulira\n",
    "\n",
    "\n",
    "\n",
    "def ulira_paper(all_unlearned_margins_ulira: ch.Tensor,\n",
    "                all_oracle_margins_ulira: ch.Tensor,\n",
    "                forget_masks,\n",
    "                training_masks,\n",
    "                plot_index=-1,\n",
    "                verbose=False,\n",
    "                max_models=None):\n",
    "    \"\"\"\n",
    "    forgettable_points_ind, # which of the forgettable points we are looking at \n",
    "\n",
    "    \"\"\"\n",
    "    #sample_ind = forgettable_points[forgettable_points_ind]\n",
    "    #oracle_count, N = training_masks.shape\n",
    "    unlearning_count = all_unlearned_margins_ulira.shape[0]  # 1000\n",
    "    target_count = unlearning_count // 2  # 500\n",
    "    target_count = 50\n",
    "    #shadow_count = int(0.1* unlearning_count)  # 500\n",
    "\n",
    "    # target models are first 500 unlearned models\n",
    "    target_unlearning_margins = all_unlearned_margins_ulira[:target_count]\n",
    "    target_oracle_margins = all_oracle_margins_ulira[:target_count]\n",
    "    target_forget_masks = forget_masks[:target_count]\n",
    "    target_training_masks = training_masks[:target_count]\n",
    "    ###\n",
    "\n",
    "    shadow_unlearning_margins = all_unlearned_margins_ulira[\n",
    "        target_count:unlearning_count]\n",
    "    shadow_oracle_margins = all_oracle_margins_ulira[\n",
    "        target_count:unlearning_count]\n",
    "    shadow_forget_masks = forget_masks[target_count:unlearning_count]\n",
    "    shadow_training_masks = training_masks[target_count:unlearning_count]\n",
    "    if False:\n",
    "        # Print statements to show shapes and sizes\n",
    "        print(\"all_unlearned_margins_ulira shape:\",\n",
    "              all_unlearned_margins_ulira.shape)\n",
    "        print(f\"unlearning_count- {unlearning_count}\")\n",
    "        print(\"all_oracle_margins_ulira shape:\",\n",
    "              all_oracle_margins_ulira.shape)\n",
    "        print(\"forget_masks shape:\", forget_masks.shape)\n",
    "        print(\"training_masks shape:\", training_masks.shape)\n",
    "\n",
    "        print(\"unlearning_count:\", unlearning_count)\n",
    "        print(\"shadow_count:\", target_count)\n",
    "\n",
    "        print(\"target_unlearning_margins shape:\",\n",
    "              target_unlearning_margins.shape)\n",
    "        print(\"target_oracle_margins shape:\", target_oracle_margins.shape)\n",
    "        print(\"target_forget_masks shape:\", target_forget_masks.shape)\n",
    "        print(\"target_training_masks shape:\", target_training_masks.shape)\n",
    "\n",
    "        print(\"shadow_unlearning_margins shape:\",\n",
    "              shadow_unlearning_margins.shape)\n",
    "        print(\"shadow_oracle_margins shape:\", shadow_oracle_margins.shape)\n",
    "        print(\"shadow_forget_masks shape:\", shadow_forget_masks.shape)\n",
    "        print(\"shadow_training_masks shape:\", shadow_training_masks.shape)\n",
    "        return\n",
    "    #print(f\"shadow_forget_masks.shape - {shadow_forget_masks.shape}\")\n",
    "    #print(f\"target_forget_masks - {target_forget_masks.shape}\")\n",
    "\n",
    "    # get the set of indices that models consider forgetting\n",
    "    forgettable_indices = list(sorted(get_forgettable_indices(forget_masks)))\n",
    "\n",
    "    model_scores = []\n",
    "    model_count = len(target_unlearning_margins)\n",
    "    if max_models is not None:\n",
    "        model_count = max_models\n",
    "\n",
    "    for model_i in range(model_count):\n",
    "        print(f\"model {model_i}\")\n",
    "        target_margins = target_unlearning_margins[model_i]\n",
    "\n",
    "        # indices that model_i forgot\n",
    "        #forget_indices = target_forget_masks[model_i].nonzero()[0]\n",
    "        target_forget_set_mask = target_forget_masks[model_i]\n",
    "        target_training_set_mask = target_training_masks[model_i]\n",
    "\n",
    "        forget_mask_ = np.array(target_forget_set_mask *\n",
    "                                target_training_set_mask,\n",
    "                                dtype=bool)\n",
    "        forget_indices = forget_mask_.nonzero()[0]\n",
    "        forget_pt_count = len(forget_indices)\n",
    "        \n",
    "        \n",
    "        test_indices = get_test_points_for_ulira(\n",
    "            forget_indices,\n",
    "            forgettable_indices,\n",
    "            num_test_points=forget_pt_count,\n",
    "            seed=42)\n",
    "\n",
    "        # take 200 points that the model never saw\n",
    "        #target_training_set_indices = target_training_set_mask.nonzero()[0]\n",
    "        #print(target_training_set_mask)\n",
    "        #target_unseen_training_mask = 1- target_training_set_mask\n",
    "        seen_training_indices = target_training_set_mask.nonzero()[0]\n",
    "        #unseen_training_indices = target_unseen_training_mask.nonzero()[0]\n",
    "        # test indiices is forgettable indices that have have never been seen by the model\n",
    "        test_indices = list(\n",
    "            set(forgettable_indices) - set(seen_training_indices))\n",
    "        test_indices = sorted(list(test_indices))[:forget_pt_count]\n",
    "        if verbose:\n",
    "            print(f\"we want a 0\")\n",
    "\n",
    "        if model_i < 3:\n",
    "            plot_index = plot_index\n",
    "        else:\n",
    "            plot_index = -1\n",
    "\n",
    "        # NOTE -  we don't want oracles. we want shadow models that never saw the point\n",
    "        #\n",
    "        test_ulira_correct = do_ulira_on_one_model(test_indices,\n",
    "                                                   0,\n",
    "                                                   target_margins,\n",
    "                                                   shadow_unlearning_margins,\n",
    "                                                   shadow_oracle_margins,\n",
    "                                                   shadow_forget_masks,\n",
    "                                                   shadow_training_masks,\n",
    "                                                   plot_index=plot_index,\n",
    "                                                   verbose=verbose)\n",
    "        if verbose:\n",
    "            print(f\"we want a 1\")\n",
    "        # forget indices\n",
    "        forget_ulira_correct = do_ulira_on_one_model(forget_indices,\n",
    "                                                     1,\n",
    "                                                     target_margins,\n",
    "                                                     shadow_unlearning_margins,\n",
    "                                                     shadow_oracle_margins,\n",
    "                                                     shadow_forget_masks,\n",
    "                                                     shadow_training_masks,\n",
    "                                                     plot_index=plot_index)\n",
    "\n",
    "        model_score = (test_ulira_correct + forget_ulira_correct) / (\n",
    "            len(test_indices) + len(forget_indices))\n",
    "        model_scores.append(model_score)\n",
    "        if verbose:\n",
    "            print(f\"test_ulira_correct- {test_ulira_correct} ||\")\n",
    "        print(f\"model - score: {model_score} - mean : {np.mean(model_scores)}\")\n",
    "    #raise\n",
    "    return (model_scores)\n",
    "\n",
    "\n",
    "noop = True# False\n",
    "if noop:\n",
    "    #forget_masks = ulira.get_ulira_forget_mask(ds_name, class_5_range=1000, overwrite=False )\n",
    "    #forget_masks_ = generate_ulira_forget_mask(dataset_name, class_5_range=5000, training_mask=training_masks)\n",
    "    print(f\"do nothing\")\n",
    "\n",
    "    m, n = non_repeated_training_masks.shape\n",
    "    num_models = non_repeated_all_oracle_margins_ulira.shape[0]\n",
    "    forgettable_masks = np.zeros((n))\n",
    "    forgettable_masks.shape\n",
    "    forgettable_masks[forgettable_indices] = 1\n",
    "\n",
    "    fake_forget_masks = []\n",
    "    print(f\"creating a fake mask \")\n",
    "\n",
    "    for training_mask in non_repeated_training_masks[:num_models]:\n",
    "        # pick 200 forgettable indices\n",
    "        forgettable_indices_200 = np.random.choice(forgettable_indices,\n",
    "                                                   200,\n",
    "                                                   replace=False)\n",
    "        forgettable_mask = forgettable_masks * training_mask\n",
    "\n",
    "        # if we want to only take 200 of these points\n",
    "        if False:\n",
    "            forgettable_mask_indices = forgettable_mask.nonzero()[0]\n",
    "            forgettable_mask_indices = np.random.choice(\n",
    "                forgettable_mask_indices, 200, replace=False)\n",
    "            forgettable_mask = np.zeros_like(training_mask)\n",
    "            forgettable_mask[forgettable_mask_indices] = 1\n",
    "\n",
    "        fake_forget_masks.append(forgettable_mask)\n",
    "    fake_forget_masks = np.array(fake_forget_masks)\n",
    "    print(f\"fake_forget_masks - {fake_forget_masks.shape}\")\n",
    "\n",
    "    model_scores = ulira_paper(non_repeated_all_oracle_margins_ulira,\n",
    "                                   non_repeated_all_oracle_margins_ulira,\n",
    "                                   fake_forget_masks,\n",
    "                                   non_repeated_training_masks,\n",
    "                                   max_models=50,\n",
    "                                   plot_index=2,\n",
    "                                   verbose=False)\n",
    "\n",
    "else:\n",
    "    model_scores = ulira_paper(all_unlearned_margins_ulira,\n",
    "                               all_oracle_margins_ulira,\n",
    "                               forget_masks,\n",
    "                               training_masks,\n",
    "                               plot_index=2,\n",
    "                               max_models=3,\n",
    "                               verbose=False)\n",
    "# 48883"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try to load ulira model 1\n",
    "def do_nothing(*args, **kwargs):\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # resnet 9!\n",
    "from torchvision import models as torchvision_models\n",
    "import torch \n",
    "from unlearning.models.resnet9 import WrappedModel\n",
    "# resnet 18\n",
    "model = torchvision_models.resnet18(num_classes=10)\n",
    "#model = ResNet9(num_classes=10)\n",
    "model= WrappedModel(model).cuda()\n",
    "#model = model.load_state_dict(torch.load(ulira_model_ckpt_paths[0]))\n",
    "\n",
    "unlearnings_per_model = 40\n",
    "print(f\"Note! we do {unlearnings_per_model} unlearnings per model! (this is hardcoded)\")\n",
    "\n",
    "all_ulira_forget_masks =get_ulira_forget_masks(ds_name, original_model_count = 256, class_5_range=1000, unlearnings_per_model = unlearnings_per_model , overwrite = False )\n",
    "i = 40\n",
    "\n",
    "original_model_i = i // unlearnings_per_model\n",
    "forget_index = i % unlearnings_per_model\n",
    "\n",
    "forget_set_mask = all_ulira_forget_masks[original_model_i][forget_index]\n",
    "# forget_set should be the set intersection of the forget mask and the ulira mask at index i\n",
    "\n",
    "ulira_mask = ulira.get_ulira_masks()\n",
    "\n",
    "training_set_mask = ulira_mask[i]\n",
    "\n",
    "#forget_set_mask = ulira_forget_mask[i]\n",
    "print(f\"forget_set_mask= {forget_set_mask.shape}\")\n",
    "print(f\"training_set_mask= {training_set_mask.shape}\")\n",
    "print(f\"type - {type(forget_set_mask)}\")\n",
    "print(f\"type - {type(training_set_mask)}\")\n",
    "# bitwise and the two masks\n",
    "train_and_forget = np.array(forget_set_mask * training_set_mask, dtype=bool)\n",
    "#train_and_forget = np.dot(forget_set_mask, training_set_mask)\n",
    "print(f\"number of forget points (real): {train_and_forget.sum()}\")\n",
    "print(f\"train_and_forget - {train_and_forget}\")\n",
    "\n",
    "forget_set_indices = (train_and_forget).nonzero()[0]\n",
    "\n",
    "print(f\"forget_set_indices- {forget_set_indices}\")\n",
    "models_dir = Path(\n",
    "    \"/n/home04/rrinberg/data_dir__holylabs/unlearning/precomputed_models/ULIRA_clean\" ) / \"final_models\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "ulira_model_ckpt_paths = [models_dir/ f\"sd_1_epoch_1.pt\" ]\n",
    "\n",
    "\n",
    "ulira_model_ckpt_path = ulira_model_ckpt_paths[original_model_i]\n",
    "print(f\"original_model_i-   {original_model_i}\")\n",
    "from unlearning.auditors.direct import (\n",
    "    get_u_margins,\n",
    ")\n",
    "\n",
    "\n",
    "train_loader = loader_factory(ds_name, indexed=True)\n",
    "val_loader = loader_factory(ds_name, split=\"val\", indexed=True)\n",
    "eval_set_inds = np.arange(\n",
    "    len(train_loader.dataset) + len(val_loader.dataset))\n",
    "\n",
    "eval_loader = loader_factory(ds_name,\n",
    "                                split=\"train_and_val\",\n",
    "                                indices=eval_set_inds,\n",
    "                                indexed=True)\n",
    "\n",
    "\n",
    "\n",
    "_m = get_u_margins(\n",
    "    model,\n",
    "    ulira_model_ckpt_path,\n",
    "    do_nothing,\n",
    "    {},\n",
    "    train_loader,\n",
    "    eval_loader,\n",
    "    forget_set_indices,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_masks.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.mean((0.8125, 0.8475,0.8425, 0.805, 0.785, 0.8325, 0.82, 0.8225, 0.7825, 0.83, 0.79))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = [\"train\", \"val\"]\n",
    "\n",
    "ulira_model_ckpt_paths, _, _ = ulira.get_ulira_model_paths(ds_name,\n",
    "                                                           splits=splits)\n",
    "ulira_model_ckpt_paths[-1]\n",
    "\n",
    "MASK_PATH = Path(\n",
    "    f\"/n/home04/rrinberg/data_dir__holylabs/unlearning/precomputed_models/ULIRA_clean/training_masks.npy\"\n",
    ")\n",
    "m = np.load(MASK_PATH)\n",
    "m.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(m[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sanity_check_1(all_unlearned_margins_ulira: ch.Tensor,\n",
    "                   all_oracle_margins_ulira: ch.Tensor,\n",
    "                   forget_masks,\n",
    "                   training_masks,\n",
    "                   plot_index=-1):\n",
    "    \"\"\"\n",
    "    forgettable_points_ind, # which of the forgettable points we are looking at \n",
    "\n",
    "    \"\"\"\n",
    "    #sample_ind = forgettable_points[forgettable_points_ind]\n",
    "    #oracle_count, N = training_masks.shape\n",
    "    unlearning_count = all_unlearned_margins_ulira.shape[0]  # 1000\n",
    "    shadow_count = unlearning_count // 2  # 500\n",
    "\n",
    "    # target models are first 500 unlearned models\n",
    "    target_unlearning_margins = all_unlearned_margins_ulira[:shadow_count]\n",
    "    target_oracle_margins = all_oracle_margins_ulira[:shadow_count]\n",
    "    target_forget_masks = forget_masks[:shadow_count]\n",
    "    target_training_masks = training_masks[:shadow_count]\n",
    "    ###\n",
    "\n",
    "    shadow_unlearning_margins = all_unlearned_margins_ulira[\n",
    "        shadow_count:unlearning_count]\n",
    "    shadow_oracle_margins = all_oracle_margins_ulira[\n",
    "        shadow_count:unlearning_count]\n",
    "    shadow_forget_masks = forget_masks[shadow_count:unlearning_count]\n",
    "    shadow_training_masks = training_masks[shadow_count:unlearning_count]\n",
    "\n",
    "    #print(f\"shadow_forget_masks.shape - {shadow_forget_masks.shape}\")\n",
    "    #print(f\"target_forget_masks - {target_forget_masks.shape}\")\n",
    "\n",
    "    # get the set of indices that models consider forgetting\n",
    "    forgettable_indices = get_forgettable_indices(forget_masks)\n",
    "    model_scores = []\n",
    "    model_count = len(target_unlearning_margins)\n",
    "    model_count = 4\n",
    "    for model_i in range(model_count):\n",
    "        print(f\"model {model_i}\")\n",
    "        # margins of model i\n",
    "        target_margins = target_unlearning_margins[model_i]\n",
    "\n",
    "        # indices that model_i forgot\n",
    "        forget_indices = target_forget_masks[model_i].nonzero()[0]\n",
    "        forget_pt_count = len(forget_indices)\n",
    "\n",
    "        test_indices = get_test_points_for_ulira(\n",
    "            forget_indices,\n",
    "            forgettable_indices,\n",
    "            num_test_points=forget_pt_count,\n",
    "            seed=42)\n",
    "\n",
    "\n",
    "        target_forget_set_mask = target_forget_masks[model_i]\n",
    "        target_training_set_mask = target_training_masks[model_i]\n",
    "\n",
    "        forget_mask_ = np.array(target_forget_set_mask *\n",
    "                                target_training_set_mask,\n",
    "                                dtype=bool)\n",
    "        forget_indices = forget_mask_.nonzero()[0]\n",
    "        forget_pt_count = len(forget_indices)\n",
    "        \n",
    "        \n",
    "        test_indices = get_test_points_for_ulira(\n",
    "            forget_indices,\n",
    "            forgettable_indices,\n",
    "            num_test_points=forget_pt_count,\n",
    "            seed=42)\n",
    "\n",
    "        seen_training_indices = target_training_set_mask.nonzero()[0]\n",
    "        test_indices = list(\n",
    "            set(forgettable_indices) - set(seen_training_indices))\n",
    "        test_indices = sorted(list(test_indices))[:forget_pt_count]\n",
    "\n",
    "\n",
    "\n",
    "        # plot histogram of margins in test and forget\n",
    "        plt.title(f\"model {model_i}\")\n",
    "        plt.hist(target_margins[forget_indices],\n",
    "                 bins=50,\n",
    "                 alpha=0.5,\n",
    "                 label=\"forget\")\n",
    "        plt.hist(target_margins[test_indices],\n",
    "                 bins=50,\n",
    "                 alpha=0.5,\n",
    "                 label=\"test\")\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "    return (model_scores)\n",
    "\n",
    "print(f\"this is plotting - model 0 on the forget set vs the test set\")\n",
    "model_scores = sanity_check_1(all_unlearned_margins_ulira,\n",
    "                            all_oracle_margins_ulira,\n",
    "                            forget_masks,\n",
    "                            training_masks,\n",
    "                            plot_index=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sanity_check_2(all_unlearned_margins_ulira: ch.Tensor,\n",
    "                   all_oracle_margins_ulira: ch.Tensor,\n",
    "                   forget_masks,\n",
    "                   training_masks,\n",
    "                   plot_index=-1):\n",
    "    \"\"\"\n",
    "    forgettable_points_ind, # which of the forgettable points we are looking at \n",
    "\n",
    "    \"\"\"\n",
    "    #sample_ind = forgettable_points[forgettable_points_ind]\n",
    "    #oracle_count, N = training_masks.shape\n",
    "    unlearning_count = all_unlearned_margins_ulira.shape[0]  # 1000\n",
    "    shadow_count = unlearning_count // 2  # 500\n",
    "\n",
    "    # target models are first 500 unlearned models\n",
    "    target_unlearning_margins = all_unlearned_margins_ulira[:shadow_count]\n",
    "    target_oracle_margins = all_oracle_margins_ulira[:shadow_count]\n",
    "    target_forget_masks = forget_masks[:shadow_count]\n",
    "    target_training_masks = training_masks[:shadow_count]\n",
    "    ###\n",
    "\n",
    "    shadow_unlearning_margins = all_unlearned_margins_ulira[\n",
    "        shadow_count:unlearning_count]\n",
    "    shadow_oracle_margins = all_oracle_margins_ulira[\n",
    "        shadow_count:unlearning_count]\n",
    "    shadow_forget_masks = forget_masks[shadow_count:unlearning_count]\n",
    "    shadow_training_masks = training_masks[shadow_count:unlearning_count]\n",
    "\n",
    "    #print(f\"shadow_forget_masks.shape - {shadow_forget_masks.shape}\")\n",
    "    #print(f\"target_forget_masks - {target_forget_masks.shape}\")\n",
    "\n",
    "    # get the set of indices that models consider forgetting\n",
    "    forgettable_indices = get_forgettable_indices(forget_masks)\n",
    "    model_scores = []\n",
    "    model_count = len(target_unlearning_margins)\n",
    "    model_count = 4\n",
    "    points_of_interest = forgettable_indices[:model_count]\n",
    "    for point_of_interest in points_of_interest:\n",
    "        # models that never saw points_of_interest\n",
    "        models_without_x, _ = get_training_models_with_and_without(\n",
    "            target_training_masks, point_of_interest)\n",
    "        # models that forgot points_of_interest\n",
    "        models_with_x_forgotten = get_models_with_pt_forgotten(\n",
    "            target_training_masks, target_forget_masks, point_of_interest)\n",
    "        # models that retained x\n",
    "        models_with_x_retained = get_models_with_pt_retained(\n",
    "            target_training_masks, target_forget_masks, point_of_interest)\n",
    "\n",
    "        unlearned_margins_of_interest = target_unlearning_margins[:,\n",
    "                                                                  point_of_interest]\n",
    "        oracle_margins_of_interest = target_oracle_margins[:,\n",
    "                                                           point_of_interest]\n",
    "\n",
    "        untrained_margins = oracle_margins_of_interest[models_without_x]\n",
    "        forgotten_margins = unlearned_margins_of_interest[models_with_x_forgotten]\n",
    "        retained_margins = oracle_margins_of_interest[models_with_x_retained]\n",
    "\n",
    "        # plot histogram of margins in test and forget\n",
    "        plt.title(f\"pt {point_of_interest}\")\n",
    "        density = True\n",
    "        plt.hist(untrained_margins,\n",
    "                 bins=50,\n",
    "                 alpha=0.5,\n",
    "                 label=\"untrained\",\n",
    "                 density=density)\n",
    "        plt.hist(forgotten_margins,\n",
    "                 bins=50,\n",
    "                 alpha=0.5,\n",
    "                 label=\"forgotten\",\n",
    "                 density=density)\n",
    "        plt.hist(retained_margins,\n",
    "                 bins=50,\n",
    "                 alpha=0.5,\n",
    "                 label=\"retained\",\n",
    "                 density=density)\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "    return\n",
    "\n",
    "\n",
    "model_scores = sanity_check_2(all_unlearned_margins_ulira,\n",
    "                            all_oracle_margins_ulira,\n",
    "                            forget_masks,\n",
    "                            training_masks,\n",
    "                            plot_index=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computation_round_2(\n",
    "    all_unlearned_margins_ulira: ch.Tensor,\n",
    "    all_oracle_margins_ulira: ch.Tensor,\n",
    "    forget_masks,\n",
    "    training_masks,\n",
    "):\n",
    "    \"\"\"\n",
    "    forgettable_points_ind, # which of the forgettable points we are looking at \n",
    "\n",
    "    \"\"\"\n",
    "    #sample_ind = forgettable_points[forgettable_points_ind]\n",
    "    #oracle_count, N = training_masks.shape\n",
    "    unlearning_count = all_unlearned_margins_ulira.shape[0]  # 1000\n",
    "    shadow_count = unlearning_count // 2  # 500\n",
    "\n",
    "    # target models are first 500 unlearned models\n",
    "    target_unlearning_margins = all_unlearned_margins_ulira[:shadow_count]\n",
    "    target_oracle_margins = all_oracle_margins_ulira[:shadow_count]\n",
    "    target_forget_masks = forget_masks[:shadow_count]\n",
    "    target_training_masks = training_masks[:shadow_count]\n",
    "    ###\n",
    "\n",
    "    shadow_unlearning_margins = all_unlearned_margins_ulira[\n",
    "        shadow_count:unlearning_count]\n",
    "    shadow_oracle_margins = all_oracle_margins_ulira[\n",
    "        shadow_count:unlearning_count]\n",
    "    shadow_forget_masks = forget_masks[shadow_count:unlearning_count]\n",
    "    shadow_training_masks = training_masks[shadow_count:unlearning_count]\n",
    "\n",
    "    #print(f\"shadow_forget_masks.shape - {shadow_forget_masks.shape}\")\n",
    "    #print(f\"target_forget_masks - {target_forget_masks.shape}\")\n",
    "\n",
    "    # get the set of indices that models consider forgetting\n",
    "    forgettable_indices = get_forgettable_indices(forget_masks)\n",
    "\n",
    "    target_model_ind = 1\n",
    "    target_model_margins = target_unlearning_margins[target_model_ind]\n",
    "    # is plot_index in forget point for index 0\n",
    "    forget_indices = target_forget_masks[target_model_ind].nonzero()[0]\n",
    "    # forgettable_indices - forget_indices\n",
    "    retain_indices = list(set(forgettable_indices) - set(forget_indices))\n",
    "\n",
    "    # indices to plot\n",
    "    num_indices = 10\n",
    "    plot_indices = list(forget_indices[:num_indices]) + list(\n",
    "        retain_indices[:num_indices])\n",
    "    #print(f\"plot_indices- {plot_indices}\")\n",
    "    #plot_index = 3\n",
    "    #plot_indices = forgettable_indices[:10]\n",
    "\n",
    "    #plot_indices = [851, 195]\n",
    "    #plot_indices = [48883]\n",
    "    total_correct = 0\n",
    "    for plot_index in plot_indices:  #[0,-1, forgettable_indices[0], forgettable_indices[1], forgettable_indices[100]]:\n",
    "        # get target_models\n",
    "        # indices that model_i forgot\n",
    "        # models with index in forget_set, and models without\n",
    "        target_models_with_index, target_models_without_index = get_training_models_with_and_without(\n",
    "            target_training_masks, plot_index)\n",
    "\n",
    "        target_margins_with = target_unlearning_margins[\n",
    "            target_models_with_index]\n",
    "        target_margins_without = target_unlearning_margins[\n",
    "            target_models_without_index]\n",
    "\n",
    "        shadow_models_with_index, shadow_models_without_index = get_training_models_with_and_without(\n",
    "            shadow_training_masks, plot_index)\n",
    "        shadow_margins_with = shadow_unlearning_margins[\n",
    "            shadow_models_with_index]\n",
    "        shadow_margins_without = shadow_unlearning_margins[\n",
    "            shadow_models_without_index]\n",
    "\n",
    "        # get models that forgot the point\n",
    "        target_models_forgot_indices = get_models_with_pt_forgotten(\n",
    "            target_training_masks, target_forget_masks, plot_index)\n",
    "\n",
    "        target_margins_forget = target_unlearning_margins[\n",
    "            target_models_forgot_indices]\n",
    "        shadow_models_forgot_indices = get_models_with_pt_forgotten(\n",
    "            shadow_training_masks, shadow_forget_masks, plot_index)\n",
    "        shadow_margins_forget = shadow_unlearning_margins[\n",
    "            shadow_models_forgot_indices]\n",
    "\n",
    "        ###\n",
    "\n",
    "        def get_gaussian_at_point(pts, ind):\n",
    "            pts_ = pts[:, ind].cpu().numpy()\n",
    "            mean, std = np.mean(pts_), np.std(pts_)\n",
    "            x = target_model_margins[ind]\n",
    "            return gaussian_pdf(x, mean, std)\n",
    "\n",
    "        forget_likelihood = get_gaussian_at_point(shadow_margins_forget,\n",
    "                                                  plot_index)\n",
    "        oracle_likelihood = get_gaussian_at_point(shadow_oracle_margins,\n",
    "                                                  plot_index)\n",
    "        likelihood_ratio = forget_likelihood / (forget_likelihood +\n",
    "                                                oracle_likelihood)\n",
    "        #cast likelihood_ratio to float\n",
    "        likelihood_ratio = float(likelihood_ratio)\n",
    "        #print(f\"likelihood_ratio {type(likelihood_ratio)}\")\n",
    "        ulira_label = int(likelihood_ratio > 0.5)\n",
    "\n",
    "        included_in_forget = plot_index in forget_indices\n",
    "\n",
    "        correct = ulira_label == included_in_forget\n",
    "        print(\n",
    "            f\"did it get it correct- {correct}? | true label - {included_in_forget} | ulira label - {ulira_label}\"\n",
    "        )\n",
    "        total_correct += int(correct)\n",
    "        if True:\n",
    "            #####\n",
    "            density = True\n",
    "            plt.title(\n",
    "                f\"margins at index {plot_index} - {round(likelihood_ratio,2)} | correct {correct}\"\n",
    "            )\n",
    "\n",
    "            def plot_hist(pts, ind, label):\n",
    "                pts_ = pts[:, ind].cpu().numpy()\n",
    "                mean, std = np.mean(pts_), np.std(pts_)\n",
    "                # plt guassian\n",
    "                x = np.linspace(-20, 20, 1000)\n",
    "                plt.plot(x, gaussian_pdf(x, mean, std), label=label)\n",
    "                # plts hist\n",
    "\n",
    "                # get prev color\n",
    "                c = plt.gca().lines[-1].get_color()\n",
    "\n",
    "                plt.hist(\n",
    "                    pts_,\n",
    "                    bins=25,\n",
    "                    alpha=0.5,\n",
    "                    #label=label,\n",
    "                    color=c,\n",
    "                    density=density)\n",
    "\n",
    "            # forget points\n",
    "            plot_hist(target_margins_forget, plot_index, \"target forget\")\n",
    "            plot_hist(shadow_margins_forget, plot_index, \"shadow forget\")\n",
    "            bin_count = 25\n",
    "            # test points\n",
    "            plot_hist(target_margins_with, plot_index, \"target with\")\n",
    "            plot_hist(shadow_margins_with, plot_index, \"shadow with\")\n",
    "            x = target_model_margins[plot_index]\n",
    "            plt.axvline(x, color=\"black\", linestyle=\"--\")\n",
    "            plt.xlim(-20, 20)\n",
    "            plt.legend()\n",
    "            plt.show()\n",
    "    print(f\"total_correct - {total_correct} / {len(plot_indices)}\")\n",
    "computation_round_2(\n",
    "    all_unlearned_margins_ulira,\n",
    "    all_oracle_margins_ulira,\n",
    "    forget_masks,\n",
    "    training_masks,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotting_investigation(\n",
    "    all_unlearned_margins_ulira: ch.Tensor,\n",
    "    all_oracle_margins_ulira: ch.Tensor,\n",
    "    forget_masks,\n",
    "    training_masks,\n",
    "):\n",
    "    \"\"\"\n",
    "    forgettable_points_ind, # which of the forgettable points we are looking at \n",
    "\n",
    "    \"\"\"\n",
    "    #sample_ind = forgettable_points[forgettable_points_ind]\n",
    "    #oracle_count, N = training_masks.shape\n",
    "    unlearning_count = all_unlearned_margins_ulira.shape[0]  # 1000\n",
    "    shadow_count = unlearning_count // 2  # 500\n",
    "\n",
    "    # target models are first 500 unlearned models\n",
    "    target_unlearning_margins = all_unlearned_margins_ulira[:shadow_count]\n",
    "    target_oracle_margins = all_oracle_margins_ulira[:shadow_count]\n",
    "    target_forget_masks = forget_masks[:shadow_count]\n",
    "    target_training_masks = training_masks[:shadow_count]\n",
    "    ###\n",
    "\n",
    "    shadow_unlearning_margins = all_unlearned_margins_ulira[\n",
    "        shadow_count:unlearning_count]\n",
    "    shadow_oracle_margins = all_oracle_margins_ulira[\n",
    "        shadow_count:unlearning_count]\n",
    "    shadow_forget_masks = forget_masks[shadow_count:unlearning_count]\n",
    "    shadow_training_masks = training_masks[shadow_count:unlearning_count]\n",
    "\n",
    "    #print(f\"shadow_forget_masks.shape - {shadow_forget_masks.shape}\")\n",
    "    #print(f\"target_forget_masks - {target_forget_masks.shape}\")\n",
    "\n",
    "    # get the set of indices that models consider forgetting\n",
    "    forgettable_indices = get_forgettable_indices(forget_masks)\n",
    "\n",
    "    target_model_ind = 1\n",
    "    target_model_margins = target_unlearning_margins[target_model_ind]\n",
    "    # is plot_index in forget point for index 0\n",
    "    forget_indices = target_forget_masks[target_model_ind].nonzero()[0]\n",
    "    # forgettable_indices - forget_indices\n",
    "    retain_indices = list(set(forgettable_indices) - set(forget_indices))\n",
    "\n",
    "    # indices to plot\n",
    "    plot_indices = list(forget_indices[:4]) + list(retain_indices[:4])\n",
    "    #print(f\"plot_indices- {plot_indices}\")\n",
    "    #plot_index = 3\n",
    "    #plot_indices = forgettable_indices[:10]\n",
    "\n",
    "    #plot_indices = [851, 195]\n",
    "    #plot_indices = [48883]\n",
    "    total_correct = 0\n",
    "    for plot_index in plot_indices:  #[0,-1, forgettable_indices[0], forgettable_indices[1], forgettable_indices[100]]:\n",
    "        # get target_models\n",
    "        # indices that model_i forgot\n",
    "        # models with index in forget_set, and models without\n",
    "        target_models_with_index, target_models_without_index = get_training_models_with_and_without(\n",
    "            target_training_masks, plot_index)\n",
    "\n",
    "        target_margins_with = target_unlearning_margins[\n",
    "            target_models_with_index]\n",
    "        target_margins_without = target_unlearning_margins[\n",
    "            target_models_without_index]\n",
    "\n",
    "        shadow_models_with_index, shadow_models_without_index = get_training_models_with_and_without(\n",
    "            shadow_training_masks, plot_index)\n",
    "        shadow_margins_with = shadow_unlearning_margins[\n",
    "            shadow_models_with_index]\n",
    "        shadow_margins_without = shadow_unlearning_margins[\n",
    "            shadow_models_without_index]\n",
    "\n",
    "        # get models that forgot the point\n",
    "        target_models_forgot_indices = get_models_with_pt_forgotten(\n",
    "            target_training_masks, target_forget_masks, plot_index)\n",
    "\n",
    "        target_margins_forget = target_unlearning_margins[\n",
    "            target_models_forgot_indices]\n",
    "        shadow_models_forgot_indices = get_models_with_pt_forgotten(\n",
    "            shadow_training_masks, shadow_forget_masks, plot_index)\n",
    "        shadow_margins_forget = shadow_unlearning_margins[\n",
    "            shadow_models_forgot_indices]\n",
    "        ###\n",
    "\n",
    "        ####\n",
    "        included_in_forget = plot_index in forget_indices\n",
    "        # shadow_models_with_index\n",
    "        # shadow_models_forgot_indices\n",
    "        # could be that model_i is inccorectly index\n",
    "        print(f\"it is included! - {included_in_forget}\")\n",
    "        test_ulira_correct = do_ulira_on_one_model([plot_index],\n",
    "                                                   included_in_forget,\n",
    "                                                   target_model_margins,\n",
    "                                                   shadow_unlearning_margins,\n",
    "                                                   #shadow_oracle_margins,\n",
    "                                                   shadow_forget_masks,\n",
    "                                                   shadow_training_masks,\n",
    "                                                   plot_index=0)\n",
    "        density = True\n",
    "        correct = test_ulira_correct == included_in_forget\n",
    "        print(f\"did it get it correct- {correct}?\")\n",
    "        total_correct += int(correct)\n",
    "        #####\n",
    "        plt.title(\n",
    "            f\"margins at index {plot_index} | model label: {test_ulira_correct}\"\n",
    "        )\n",
    "\n",
    "        def plot_hist(pts, ind, label):\n",
    "            pts_ = pts[:, ind].cpu().numpy()\n",
    "            mean, std = np.mean(pts_), np.std(pts_)\n",
    "            # plt guassian\n",
    "            x = np.linspace(-20, 20, 1000)\n",
    "            plt.plot(x, gaussian_pdf(x, mean, std), label=label)\n",
    "            # plts hist\n",
    "            # get prev color\n",
    "            c = plt.gca().lines[-1].get_color()\n",
    "\n",
    "            plt.hist(\n",
    "                pts_,\n",
    "                bins=25,\n",
    "                alpha=0.5,\n",
    "                #label=label,\n",
    "                color=c,\n",
    "                density=density)\n",
    "\n",
    "        # forget points\n",
    "        plot_hist(target_margins_forget, plot_index, \"target forget\")\n",
    "        plot_hist(shadow_margins_forget, plot_index, \"shadow forget\")\n",
    "        if False:\n",
    "            plt.hist(target_margins_forget[:, plot_index].cpu().numpy(),\n",
    "                     bins=25,\n",
    "                     alpha=0.5,\n",
    "                     label=\"target forget\",\n",
    "                     density=density)\n",
    "            plt.hist(shadow_margins_forget[:, plot_index].cpu().numpy(),\n",
    "                     bins=25,\n",
    "                     alpha=0.5,\n",
    "                     label=\"shadow forget\",\n",
    "                     density=density)\n",
    "        ####\n",
    "        bin_count = 25\n",
    "        # test points\n",
    "        plot_hist(target_margins_with, plot_index, \"target with\")\n",
    "        plot_hist(shadow_margins_with, plot_index, \"shadow with\")\n",
    "        if False:\n",
    "            plt.hist(target_margins_without[:, plot_index].cpu().numpy(),\n",
    "                     bins=bin_count,\n",
    "                     alpha=0.5,\n",
    "                     label=\"target without\",\n",
    "                     density=density)\n",
    "            plt.hist(shadow_margins_without[:, plot_index].cpu().numpy(),\n",
    "                     bins=bin_count,\n",
    "                     alpha=0.5,\n",
    "                     label=\"shadow without\",\n",
    "                     density=density)\n",
    "        plt.xlim(-20, 20)\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "    print(f\"total_correct - {total_correct} / {len(plot_indices)}\")\n",
    "plotting_investigation(\n",
    "    all_unlearned_margins_ulira,\n",
    "    all_oracle_margins_ulira,\n",
    "    forget_masks,\n",
    "    training_masks,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# my confusion is "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = np.mean(forget_ulira_scores)\n",
    "std = np.std(forget_ulira_scores)\n",
    "method_name = \"GA\"\n",
    "plt.hist(forget_ulira_scores)\n",
    "plt.title(f\"ULIRA scores - {method_name}\")\n",
    "plt.xlabel(\"ULIRA score\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "# vert line at mean\n",
    "plt.axvline(mean, color='k', linestyle='dashed', linewidth=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forget_masks[:4].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_masks.shape\n",
    "forget_masks.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"fall_unlearned_margins_ulira. - {all_unlearned_margins_ulira.shape }\") # 1000 x N \n",
    "print(f\"all_oracle_margins_ulira. - {all_oracle_margins_ulira.shape }\") # 2000 x N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import torch as ch\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "from typing import List, Optional\n",
    "\n",
    "from unlearning.unlearning_algos.utils import get_margin\n",
    "from unlearning.auditors.direct import (\n",
    "    direct_audit_precomputed,\n",
    "    get_u_margins,\n",
    "    u_margin_job,\n",
    "    plot_margins_direct,\n",
    ")\n",
    "from scipy.stats import norm\n",
    "import torch\n",
    "from unlearning.auditors.utils import (\n",
    "    loader_factory,\n",
    " )\n",
    "\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "import yaml\n",
    "import numpy as np\n",
    "import torch as ch\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "import logging\n",
    "import pprint\n",
    "from contextlib import redirect_stdout, redirect_stderr\n",
    "\n",
    "from unlearning.auditors.utils import (\n",
    "    model_factory,\n",
    "    loader_factory,\n",
    "    load_forget_set_indices,\n",
    "    get_full_model_paths,\n",
    "\n",
    "    get_oracle_paths,\n",
    "    make_results_dir,\n",
    ")\n",
    "from unlearning.auditors.accuracies import eval_accuracy\n",
    "from unlearning.auditors.logit_plots import compute_logits, plot_logits\n",
    "from unlearning.auditors.basic import plot_margins\n",
    "\n",
    "from unlearning.auditors.direct import (\n",
    "    config_submitit,\n",
    "    direct_audit_precomputed,\n",
    "    get_u_margins,\n",
    "    u_margin_job,\n",
    "    plot_margins_direct,\n",
    ")\n",
    "from unlearning.auditors import ulira\n",
    "from unlearning.unlearning_algos.base_nn import NAME_TO_ALGO\n",
    "\n",
    "\n",
    "from contextlib import redirect_stdout, redirect_stderr\n",
    "\n",
    "\n",
    "# 1. fix ulira accuracy measure! get test scores too !\n",
    "# 2.  \n",
    "# \n",
    "\n",
    "# load model from chkpt and evaluate accuracy \n",
    "\n",
    "\n",
    "def _model_factory(dataset, wrapped=True):\n",
    "    \"\"\"\n",
    "    for now, let's tie the model to the dataset, so we have fewer moving pieces\n",
    "    \"\"\"\n",
    "    if dataset.lower() == \"cifar10\":\n",
    "        from unlearning.models.resnet9 import ResNet9\n",
    "\n",
    "        return ResNet9(num_classes=10, wrapped=wrapped)\n",
    "\n",
    "    elif dataset.lower() == \"cifar100\":\n",
    "        from unlearning.models.resnet9 import ResNet9\n",
    "\n",
    "        return ResNet9(num_classes=100)\n",
    "    else:\n",
    "        raise NotImplementedError\n",
    "\n",
    "ds_name = \"CIFAR10\"\n",
    "# for now, let's tie the model to the dataset, so we have fewer moving pieces\n",
    "model = _model_factory(ds_name)  # on cuda, in eval mode\n",
    "model\n",
    "\n",
    "with redirect_stdout(open(\"/dev/null\", \"w\")):\n",
    "    # no shuffling, no augmentation\n",
    "    train_loader = loader_factory(ds_name, indexed=True)\n",
    "    val_loader = loader_factory(ds_name, split=\"val\", indexed=True)\n",
    "    eval_set_inds = np.arange(\n",
    "        len(train_loader.dataset) + len(val_loader.dataset))\n",
    "    eval_loader = loader_factory(ds_name,\n",
    "                                    split=\"train_and_val\",\n",
    "                                    indices=eval_set_inds,\n",
    "                                    indexed=True)\n",
    "    \n",
    "splits = [\"train\", \"val\"]\n",
    "ulira_model_ckpt_paths, _, _ = ulira.get_ulira_model_paths(ds_name,\n",
    "                                                            splits=splits)\n",
    "#ulira_mask = ulira.get_ulira_masks(ds_name)\n",
    "#ulira_forget_mask = ulira.get_ulira_forget_mask(ds_name)\n",
    "\n",
    "#logger.info(f\"Loaded paths of pretrained models.\")\n",
    "\n",
    "model = load_model(ulira_model_ckpt_paths[0], _model_factory, ds_name)\n",
    "\n",
    "#logger.info(f\"Loaded a pretrained model.\")\n",
    "####### END OF LOADING PRETRAINED MODELS ########\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# working version:\n",
    "# get 200 points from class 5 that are not from the forgettable_points\n",
    "#forgettable_indices\n",
    "def get_test_points_for_ulira(forget_indices, forgettable_indices, num_test_points=200, seed = 42):\n",
    "    \"\"\"\n",
    "    get 200 points forgettable points from class 5 that are not in the forget_indices\n",
    "    \"\"\"\n",
    "    np.random.seed(seed)\n",
    "    # copy forgettable_indices\n",
    "    class_5 = forgettable_indices.copy()\n",
    "    class_5 = np.array(list(set(class_5) - set(forget_indices)))\n",
    "    np.random.shuffle(class_5)\n",
    "    return list(class_5)[:num_test_points]\n",
    "\n",
    "def gaussian_pdf(x, mean, std):\n",
    "    return 1 / (std * np.sqrt(2 * np.pi)) * np.exp(-0.5 * ((x - mean) / std) ** 2)\n",
    "\n",
    "\n",
    "def single_ulira(\n",
    "        all_unlearned_margins: ch.Tensor,  # T x n\n",
    "        all_test_margins: ch.Tensor,  # T x n\n",
    "        unlearned_model_margin: float,\n",
    "        sample_ind,\n",
    "        threshold=0.5,\n",
    "        plot=False, verbose= False ):\n",
    "    \"\"\"\n",
    "    Compute the ULIRA (Unlearning Likelihood Ratio) results for each sample. for a single unlearned model.\n",
    "\n",
    "    Note: \n",
    "        1: (x,y) is likely a member of training (unlearned model)\n",
    "        0: (x,y) is likely a member of the oracle (oracle model)\n",
    "\n",
    "    Args:\n",
    "        all_unlearned_margins (ch.Tensor): Tensor of shape T x n containing the margins of all unlearned models.\n",
    "        all_oracle_margins (ch.Tensor): Tensor of shape T x n containing the margins of all oracle models.\n",
    "        hold_out_model (int): Index of the hold-out model.\n",
    "        threshold (float, optional): Threshold value for the likelihood ratio. Defaults to 0.5.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: Array of ULIRA results for each sample, where 1 indicates the likelihood ratio is above the threshold, and 0 otherwise.\n",
    "    \"\"\"\n",
    "    #\n",
    "    test_margins = all_test_margins[:, sample_ind].cpu().numpy()\n",
    "\n",
    "    unlearned_margins= all_unlearned_margins[:, sample_ind].cpu().numpy()\n",
    "\n",
    "    #\n",
    "    #unlearned_model_margin = unlearned_margins[hold_out_model]\n",
    "    #other_unlearned_models = np.delete(unlearned_margins, hold_out_model)\n",
    "\n",
    "    # fit gaussians\n",
    "    test_mean, test_std = np.mean(test_margins), np.std(test_margins)\n",
    "    unlearned_mean, unlearned_std = np.mean(unlearned_margins), np.std(\n",
    "        unlearned_margins)\n",
    "    #print(f\"aaa ({np.round(oracle_mean,2)}, {np.round(oracle_std,2)}) vs ({np.round(unlearned_mean,2)}, {np.round(unlearned_std,2)})\")\n",
    "    # compute LIRA\n",
    "    unlearned_model_margin = float(unlearned_model_margin)\n",
    "\n",
    "    oracle_prob = gaussian_pdf(unlearned_model_margin, test_mean, test_std)\n",
    "    unlearned_prob = gaussian_pdf(unlearned_model_margin, unlearned_mean,\n",
    "                                  unlearned_std)\n",
    "\n",
    "    likelihood_ratio = unlearned_prob / (unlearned_prob + oracle_prob)\n",
    "\n",
    "    # print(f\"likelihood_ratio - {likelihood_ratio} : type - {type(likelihood_ratio)}\")\n",
    "\n",
    "    likelihood_ratio = float(likelihood_ratio)\n",
    "    if verbose:\n",
    "        print(f\"unlearned_margins shape - {unlearned_margins.shape}\")\n",
    "        print(f\"oracle_margins shape - {test_margins.shape}\")\n",
    "        print(f\"oracle_margins - {test_margins}\")\n",
    "        \n",
    "    if plot:\n",
    "        # plot gaussians\n",
    "        plt.xlim(-20, 20)\n",
    "        x = np.linspace(-20, 20, 1000)\n",
    "        plt.hist(test_margins,\n",
    "                 bins=50,\n",
    "                 alpha=0.5,\n",
    "                 label=\"oracle\",\n",
    "                 density=True)\n",
    "        plt.hist(unlearned_margins,\n",
    "                 bins=50,\n",
    "                 alpha=0.5,\n",
    "                 label=\"unlearned\",\n",
    "                 density=True)\n",
    "        oracle_pdf = gaussian_pdf(x, test_mean, test_std)\n",
    "        unlearned_pdf = gaussian_pdf(x, unlearned_mean, unlearned_std)\n",
    "        plt.title(\n",
    "            f\"sample index: {sample_ind} | likelihood ratio: {round(likelihood_ratio,2):.2f} = {round(unlearned_prob,2)} / ({round(unlearned_prob,2)} + {round(oracle_prob,2)})\"\n",
    "        )\n",
    "        plt.plot(x, oracle_pdf, label=\"oracle\")\n",
    "        plt.plot(x, unlearned_pdf, label=\"unlearned\")\n",
    "        plt.axvline(unlearned_model_margin, color=\"black\", linestyle=\"--\")\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "    # save result\n",
    "    return float(likelihood_ratio > threshold)\n",
    "\n",
    "\n",
    "\n",
    "#####\n",
    "def get_training_models_with_and_without(masks, index):\n",
    "    \"\"\"\n",
    "    return indices of models with and without the point\n",
    "    \"\"\"\n",
    "    m = masks[:, index].T\n",
    "\n",
    "    with_index, without_index = np.where(m == 1)[0], np.where(m == 0)[0]\n",
    "    return with_index, without_index\n",
    "\n",
    "\n",
    "\n",
    "def get_models_with_pt_forgotten(masks, forget_mask, sample_index):\n",
    "    \"\"\"\n",
    "    find the indices where the point is in the plan and in the forget mask\n",
    "    \"\"\"\n",
    "\n",
    "    models_with = []\n",
    "    models_inds_with, _ = get_training_models_with_and_without(\n",
    "    masks, sample_index)\n",
    "\n",
    "    for model_ind in models_inds_with:\n",
    "        if forget_mask[model_ind, sample_index] == 1:\n",
    "            models_with.append(model_ind)\n",
    "    return np.array(models_with)\n",
    "\n",
    "def get_models_with_pt_retained(masks, forget_mask, sample_index):\n",
    "    \"\"\"\n",
    "    find the indices where the point is in the plan and in the forget mask\n",
    "    \"\"\"\n",
    "\n",
    "    models_with = []\n",
    "    models_inds_with, _ = get_training_models_with_and_without(\n",
    "    masks, sample_index)\n",
    "\n",
    "    for model_ind in models_inds_with:\n",
    "        if forget_mask[model_ind, sample_index] == 0:\n",
    "            models_with.append(model_ind)\n",
    "    return np.array(models_with)\n",
    "#####\n",
    "\n",
    "def do_ulira_on_one_model(indices,\n",
    "                          correct_ulira_label,\n",
    "                          target_margins,\n",
    "                          shadow_unlearning_margins,\n",
    "                          shadow_oracle_margins,\n",
    "                          forget_masks,\n",
    "                          training_masks,\n",
    "                          plot_index=-1, verbose=  False ):\n",
    "    \"\"\"\n",
    "\n",
    "    \"\"\"\n",
    "    correct_ulira = 0\n",
    "    ulira_labels = []\n",
    "    for i, sample_index in enumerate(indices):\n",
    "\n",
    "        # get models with x forgotten and models that never saw x\n",
    "        models_with_x_forgotten = get_models_with_pt_forgotten(\n",
    "            training_masks, forget_masks, sample_index)\n",
    "        _, models_without_x = get_training_models_with_and_without(\n",
    "            training_masks, sample_index)\n",
    "\n",
    "        num_models_with_x_forgotten = len(models_with_x_forgotten)\n",
    "        num_models_without_x = len(models_without_x)\n",
    "        if verbose:\n",
    "            print(f\"num_models_with_x_forgotten - {num_models_with_x_forgotten}\")\n",
    "            print(f\"num_models_without_x - {num_models_without_x}\")\n",
    "\n",
    "        max_models = 300\n",
    "\n",
    "        min_models = min(num_models_with_x_forgotten, num_models_without_x)\n",
    "        min_models = min(max_models, min_models)\n",
    "        #\n",
    "        #print(f\"min models - {min_models    }\")\n",
    "        #min_models = -1\n",
    "        np.random.shuffle(unlearned_models_with_x_forgotten)\n",
    "        np.random.shuffle(models_without_x)\n",
    "\n",
    "        models_with_x_forgotten = models_with_x_forgotten[:min_models]\n",
    "        models_without_x = models_without_x[:min_models]\n",
    "\n",
    "        # the margin of the target model on sample index\n",
    "        target_margin = target_margins[sample_index]\n",
    "\n",
    "        # we want to do a lira test between unlearned models that saw x\n",
    "        # and unlearned models that did not see x\n",
    "\n",
    "        ulira_label = single_ulira(\n",
    "            shadow_unlearning_margins[models_with_x_forgotten],\n",
    "            shadow_unlearning_margins[models_without_x],\n",
    "            target_margin,\n",
    "            sample_index,\n",
    "            plot=(i == plot_index), verbose= verbose)\n",
    "        if False:\n",
    "            ulira_label = single_ulira(\n",
    "                shadow_unlearning_margins[models_with_x_forgotten],\n",
    "                shadow_oracle_margins[models_without_x],\n",
    "                target_margin,\n",
    "                sample_index,\n",
    "                plot=(i == plot_index))\n",
    "        ulira_labels.append(ulira_label)\n",
    "        if ulira_label == correct_ulira_label:\n",
    "            correct_ulira += 1\n",
    "    return correct_ulira\n",
    "\n",
    "\n",
    "\n",
    "def ulira_paper(all_unlearned_margins_ulira: ch.Tensor,\n",
    "                all_oracle_margins_ulira: ch.Tensor,\n",
    "                forget_masks,\n",
    "                training_masks,\n",
    "                plot_index=-1,\n",
    "                verbose=False,\n",
    "                max_models=None):\n",
    "    \"\"\"\n",
    "    forgettable_points_ind, # which of the forgettable points we are looking at \n",
    "\n",
    "    \"\"\"\n",
    "    #sample_ind = forgettable_points[forgettable_points_ind]\n",
    "    #oracle_count, N = training_masks.shape\n",
    "    unlearning_count = all_unlearned_margins_ulira.shape[0]  # 1000\n",
    "    shadow_count = unlearning_count // 2  # 500\n",
    "\n",
    "    # target models are first 500 unlearned models\n",
    "    target_unlearning_margins = all_unlearned_margins_ulira[:shadow_count]\n",
    "    target_oracle_margins = all_oracle_margins_ulira[:shadow_count]\n",
    "    target_forget_masks = forget_masks[:shadow_count]\n",
    "    target_training_masks = training_masks[:shadow_count]\n",
    "    ###\n",
    "\n",
    "    shadow_unlearning_margins = all_unlearned_margins_ulira[\n",
    "        shadow_count:unlearning_count]\n",
    "    shadow_oracle_margins = all_oracle_margins_ulira[\n",
    "        shadow_count:unlearning_count]\n",
    "    shadow_forget_masks = forget_masks[shadow_count:unlearning_count]\n",
    "    shadow_training_masks = training_masks[shadow_count:unlearning_count]\n",
    "    very_verbose=  False\n",
    "    if very_verbose:\n",
    "        # Print statements to show shapes and sizes\n",
    "        print(\"all_unlearned_margins_ulira shape:\",\n",
    "            all_unlearned_margins_ulira.shape)\n",
    "        print(f\"unlearning_count- {unlearning_count}\")\n",
    "        print(\"all_oracle_margins_ulira shape:\", all_oracle_margins_ulira.shape)\n",
    "        print(\"forget_masks shape:\", forget_masks.shape)\n",
    "        print(\"training_masks shape:\", training_masks.shape)\n",
    "\n",
    "        print(\"unlearning_count:\", unlearning_count)\n",
    "        print(\"shadow_count:\", shadow_count)\n",
    "\n",
    "        print(\"target_unlearning_margins shape:\", target_unlearning_margins.shape)\n",
    "        print(\"target_oracle_margins shape:\", target_oracle_margins.shape)\n",
    "        print(\"target_forget_masks shape:\", target_forget_masks.shape)\n",
    "        print(\"target_training_masks shape:\", target_training_masks.shape)\n",
    "\n",
    "        print(\"shadow_unlearning_margins shape:\", shadow_unlearning_margins.shape)\n",
    "        print(\"shadow_oracle_margins shape:\", shadow_oracle_margins.shape)\n",
    "        print(\"shadow_forget_masks shape:\", shadow_forget_masks.shape)\n",
    "        print(\"shadow_training_masks shape:\", shadow_training_masks.shape)\n",
    "        return\n",
    "    #print(f\"shadow_forget_masks.shape - {shadow_forget_masks.shape}\")\n",
    "    #print(f\"target_forget_masks - {target_forget_masks.shape}\")\n",
    "\n",
    "    # get the set of indices that models consider forgetting\n",
    "    forgettable_indices = list(sorted(get_forgettable_indices(forget_masks)))\n",
    "\n",
    "    model_scores = []\n",
    "    model_count = len(target_unlearning_margins)\n",
    "    if max_models is not None:\n",
    "        model_count = max_models\n",
    "\n",
    "    for model_i in range(model_count):\n",
    "        print(f\"model {model_i}\")\n",
    "        target_margins = target_unlearning_margins[model_i]\n",
    "\n",
    "        # indices that model_i forgot\n",
    "        #forget_indices = target_forget_masks[model_i].nonzero()[0]\n",
    "        target_forget_set_mask = target_forget_masks[model_i]\n",
    "        target_training_set_mask = target_training_masks[model_i]\n",
    "\n",
    "        forget_mask_ = np.array(target_forget_set_mask *\n",
    "                                target_training_set_mask,\n",
    "                                dtype=bool)\n",
    "        forget_indices = forget_mask_.nonzero()[0]\n",
    "        forget_pt_count = len(forget_indices)\n",
    "        \n",
    "        \n",
    "        test_indices = get_test_points_for_ulira(\n",
    "            forget_indices,\n",
    "            forgettable_indices,\n",
    "            num_test_points=forget_pt_count,\n",
    "            seed=42)\n",
    "\n",
    "        # take 200 points that the model never saw\n",
    "        #target_training_set_indices = target_training_set_mask.nonzero()[0]\n",
    "        #print(target_training_set_mask)\n",
    "        #target_unseen_training_mask = 1- target_training_set_mask\n",
    "        seen_training_indices = target_training_set_mask.nonzero()[0]\n",
    "        #unseen_training_indices = target_unseen_training_mask.nonzero()[0]\n",
    "        # test indiices is forgettable indices that have have never been seen by the model\n",
    "        test_indices = list(\n",
    "            set(forgettable_indices) - set(seen_training_indices))\n",
    "        test_indices = sorted(list(test_indices))[:forget_pt_count]\n",
    "        if verbose:\n",
    "            print(f\"we want a 0\")\n",
    "\n",
    "        if model_i == 0:\n",
    "            plot_index = plot_index\n",
    "        else:\n",
    "            plot_index = -1\n",
    "\n",
    "        # NOTE -  we don't want oracles. we want shadow models that never saw the point\n",
    "        #\n",
    "        test_ulira_correct = do_ulira_on_one_model(test_indices,\n",
    "                                                   0,\n",
    "                                                   target_margins,\n",
    "                                                   shadow_unlearning_margins,\n",
    "                                                   shadow_oracle_margins,\n",
    "                                                   shadow_forget_masks,\n",
    "                                                   shadow_training_masks,\n",
    "                                                   plot_index=plot_index, verbose=verbose)\n",
    "        if verbose:\n",
    "            print(f\"we want a 1\")\n",
    "        # forget indices\n",
    "        forget_ulira_correct = do_ulira_on_one_model(forget_indices,\n",
    "                                                     1,\n",
    "                                                     target_margins,\n",
    "                                                     shadow_unlearning_margins,\n",
    "                                                     shadow_oracle_margins,\n",
    "                                                     shadow_forget_masks,\n",
    "                                                     shadow_training_masks,\n",
    "                                                     plot_index=plot_index)\n",
    "\n",
    "        model_score = (test_ulira_correct + forget_ulira_correct) / (\n",
    "            len(test_indices) + len(forget_indices))\n",
    "        model_scores.append(model_score)\n",
    "        if verbose:\n",
    "            print(f\"test_ulira_correct- {test_ulira_correct} ||\")\n",
    "        print(f\"model - score: {model_score} - mean : {np.mean(model_scores)}\")\n",
    "    #raise\n",
    "    return (model_scores)\n",
    "\n",
    "\n",
    "\n",
    "noop = True# False\n",
    "if noop:\n",
    "    #forget_masks = ulira.get_ulira_forget_mask(ds_name, class_5_range=1000, overwrite=False )\n",
    "    #forget_masks_ = generate_ulira_forget_mask(dataset_name, class_5_range=5000, training_mask=training_masks)\n",
    "    print(f\"do nothing\")\n",
    "    model_scores = ulira_paper(repeated_all_oracle_margins_ulira,\n",
    "                               repeated_all_oracle_margins_ulira,\n",
    "                               forget_masks,\n",
    "                               repeated_training_masks,\n",
    "                               max_models= 1,\n",
    "                               plot_index=2, verbose= True)\n",
    "\n",
    "else:\n",
    "    model_scores = ulira_paper(all_unlearned_margins_ulira,\n",
    "                               all_oracle_margins_ulira,\n",
    "                               forget_masks,\n",
    "                               training_masks,\n",
    "                               plot_index=-1,\n",
    "                               max_models=100,\n",
    "                               verbose=False)\n",
    "# 48883"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
