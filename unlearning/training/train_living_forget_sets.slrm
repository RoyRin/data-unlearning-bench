#!/bin/sh
#SBATCH --job-name=retrain-living17-forget
#SBATCH --array=0-39  # 4 forget sets Ã— 10 machines
#SBATCH --partition=kempner_requeue
#SBATCH --gres=gpu:1
#SBATCH --mem=80G
#SBATCH -t 0-72:00
#SBATCH -c 1
#SBATCH --output=/n/home04/rrinberg/catered_out/klom/living17-forget-%A__%a.out
#SBATCH --mail-user=royrinberg@gmail.com  
#SBATCH --mail-type=ALL
#SBATCH --account kempner_emalach_lab

# Create logs directory if it doesn't exist
mkdir -p logs

# Calculate which forget set and machine this job is for
FORGET_SET_ID=$((SLURM_ARRAY_TASK_ID / 10 + 1))  # 1-4
MACHINE_ID=$((SLURM_ARRAY_TASK_ID % 10))         # 0-9

# Calculate model indices for this machine
# Each machine trains 10 models
IDX_START=$((MACHINE_ID * 10))
N_MODELS=10

echo "Running job for forget set $FORGET_SET_ID on machine $MACHINE_ID"
echo "Training models $IDX_START to $((IDX_START + N_MODELS - 1))"

export LD_LIBRARY_PATH=/n/holylabs/LABS/vadhan_lab/Lab/rrinberg/envs/ffcv/lib:$LD_LIBRARY_PATH

# Calculate which forget set and model this job should run
# We have 4 cases (1, 2, 3, 4) and 10 models per case
# So total of 40 jobs (0-39)
FORGET_SET_ID=$((SLURM_ARRAY_TASK_ID / 10 + 1))  # +1 to start from forget set 1
MODEL_ID=$((SLURM_ARRAY_TASK_ID % 10))

# Set forget set argument
FORGET_ARG="--unlearning.forget_set_id $FORGET_SET_ID"

# Activate conda environment
source ~/.bashrc

module load python/3.10.12-fasrc01

module load intelpython/3.9.16-fasrc01
module load cuda cudnn


conda activate ffcv

cd /n/home04/rrinberg/code/data-unlearning-bench/unlearning/training

# Run the training script with fastargs parameters
python train_living.py \
    --unlearning.forget_set_id $FORGET_SET_ID \
    --unlearning.idx_start $IDX_START \
    --unlearning.n_models $N_MODELS \
    --unlearning.model_id_offset 0 \
    --training.batch_size 1024 \
    --training.epochs 25

echo "Job completed successfully" 